Ğ›Ğš 6-2024.
I. ĞŸĞµÑ€ĞµĞºÑ€ĞµÑÑ‚Ğ½Ğ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ. Ğ¡Ğ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğº. Ğ”Ğ²Ğ¾Ğ¸Ñ‡Ğ½Ğ°Ñ Ğ¿ĞµÑ€ĞµĞºÑ€ĞµÑÑ‚Ğ½Ğ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ.
II. Ğ¡Ğ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ¸.
III. Ğ¡Ğ»Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ¿Ğ¾ Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼Ñƒ.
IV. Ğ¡Ğ»Ğ¾Ğ¹ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.
V. ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ padding = 'same' / 'valid'.
VI. ĞŸĞ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°ÑÑ‰Ğ¸Ğµ ÑĞ¾ÑÑ‚ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ ÑĞµÑ‚Ğ¸. GAN.
VII. cGAN.
VIII. Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ GAN
IX. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ°/Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹.
X. ĞœĞµÑ‚Ğ¾Ğ´ ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾.
XI. ĞšĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹
XII. Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ¸ 11 Ğ¸ 12

I. ĞŸĞµÑ€ĞµĞºÑ€ĞµÑÑ‚Ğ½Ğ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ. Ğ¡Ğ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğº. Ğ”Ğ²Ğ¾Ğ¸Ñ‡Ğ½Ğ°Ñ Ğ¿ĞµÑ€ĞµĞºÑ€ĞµÑÑ‚Ğ½Ğ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ
ĞŸĞµÑ€ĞµĞºÑ€ĞµÑÑ‚Ğ½Ğ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ (Cross Entropy, CE) - Ğ¼ĞµÑ€Ğ° Ñ‚Ğ¾Ğ³Ğ¾, Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ½Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğµ Ğ½Ğ° Ğ´Ñ€ÑƒĞ³Ğ¾Ğµ.
ĞŸĞµÑ€ĞµĞºÑ€ĞµÑÑ‚Ğ½Ğ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ Ğ² Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ñ… Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸ĞºĞ¸ - Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ°Ñ Ğ´Ğ»Ğ¸Ğ½Ğ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ² Ğ±Ğ¸Ñ‚Ğ°Ñ… Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ 
Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Q Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ P,
Ğ³Ğ´Ğµ P â€“ Ğ¸ÑÑ‚Ğ¸Ğ½Ğ½Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ,
Q - Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ ÑĞ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ: 

H(ğ‘,ğ‘) = âˆ’âˆ« ğ‘(ğ‘¥) ğ‘™ğ‘œğ‘” ğ‘(ğ‘¥)ğ‘‘ğ‘¥ (ğ‘™ğ‘œğ‘” - Ğ½Ğ°Ñ‚ÑƒÑ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ»Ğ¾Ğ³Ğ°Ñ€Ğ¸Ñ„Ğ¼).
	  ğ‘¥
Ğ’ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ñ… Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
P: ğ‘¦ = y_true - one-hot-Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚ĞºĞ¸;
Q: ğ‘ = y_pred - Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:

ğ¶ğ¸(ğ‘¦, ğ‘) = âˆ’âˆ‘ ğ‘¦ğ‘– ğ‘™ğ‘œğ‘” ğ‘ğ‘– (ÑÑƒĞ¼Ğ¼Ğ° Ğ±ĞµÑ€ĞµÑ‚ÑÑ Ğ¾Ñ‚ 1 Ğ´Ğ¾ n = len(y_true) = len(y_pred)).

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€.
import keras
import numpy as np
y_true = np.array([[0, 1, 0], [0, 0, 1]])
y_pred = np.array([[0.05, 0.9, 0.05], [0.1, 0.8, 0.1]])
cce = keras.losses.CategoricalCrossentropy() # reduction = 'sum'
print(cce(y_true, y_pred)) # 1.177
print(-(np.log(0.95) + np.log(0.1)) / 2) # 1.177

# Ğ¡Ğ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğº 
cce = keras.losses.CategoricalCrossentropy(label_smoothing = 0.3)
y_true_s = np.array([[0.1, 0.8, 0.1], [0.1, 0.1, 0.8]])
# Ğ’Ğ¼ĞµÑÑ‚Ğ¾ [0, 1, 0] Ğ¸Ğ¼ĞµĞµĞ¼: [0.1, 0.8, 0.1]
# 0.1 = 0.3 / num_classes
# 0.8 = (1 - 0.3) + 0.3 / num_classes
c = -np.vdot(y_true_s, np.log(y_pred)) / 2
print(cce(y_true, y_pred)) # 1.389
print(c) # 1.389
Ğ¡Ğ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğº ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ, Ñ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ Ğ¼ĞµÑ‚ĞºÑƒ.
Ğ¡Ğ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğº - Ğ¼ĞµÑ‚Ğ¾Ğ´ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğº Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ.

Ğ”Ğ²Ğ¾Ğ¸Ñ‡Ğ½Ğ°Ñ Ğ¿ĞµÑ€ĞµĞºÑ€ĞµÑÑ‚Ğ½Ğ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ (Binary Cross Entropy, BCE).
Ğ’ ÑÑ‚Ğ¾Ğ¼ ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ¾Ğ´Ğ¸Ğ½ ĞºĞ»Ğ°ÑÑ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ ĞºĞ°Ğº Ğ¸ÑÑ‚Ğ¸Ğ½Ğ½Ñ‹Ğ¹ (Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹), Ğ° Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ 
ĞºĞ»Ğ°ÑÑÑ‹ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ ĞºĞ°Ğº Ñ„Ğ¾Ğ½ (background), Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ ĞºĞ°Ğº Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹. 
Ğ¢Ğ¾Ğ³Ğ´Ğ° BCE Ğ·Ğ°Ğ´Ğ°Ñ‘Ñ‚ÑÑ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¾Ğ¹: 

ğµğ¶ğ¸(ğ‘¦, ğ‘) = âˆ’(ğ‘¦ ğ‘™ğ‘œğ‘” ğ‘ + (1 âˆ’ ğ‘¦) ğ‘™ğ‘œğ‘”(1 âˆ’ ğ‘)).

C Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¿ĞµÑ€ĞµĞºÑ€ĞµÑÑ‚Ğ½Ğ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ - ÑÑ‚Ğ¾ Ğ»Ğ¾Ğ³Ğ°Ñ€Ğ¸Ñ„Ğ¼ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ°Ğ²Ğ´Ğ¾Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ¸Ñ: 

ğ¿(ğ‘¥) = âˆ ğ‘(ğ‘¥)ğ‘¦(ğ‘¥),
	ğ‘¥
ğ‘™(ğ‘¥) = ğ‘™ğ‘œğ‘” ğ¿ = âˆ‘ ğ‘¦(ğ‘¥) ğ‘™ğ‘œğ‘” ğ‘(ğ‘¥).
	      ğ‘¥
Ğ•ÑĞ»Ğ¸ ğ‘¦(ğ‘¥) âˆˆ {0, 1}, Ñ‚Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ¼:

ğ‘™(ğ‘, ğ‘¦) = ğ‘¦ ğ‘™ğ‘œğ‘” ğ‘ + (1 âˆ’ ğ‘¦) ğ‘™ğ‘œğ‘”(1 âˆ’ ğ‘).

ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ñ Ğ¾Ñ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡Ğµ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ ğ‘™(ğ‘¥) Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ¼: 

min ğ‘™(ğ‘¦, ğ‘) = âˆ’max ğ‘™(ğ‘¦,ğ‘) = âˆ’(ğ‘¦ ğ‘™ğ‘œğ‘” ğ‘ + (1 âˆ’ ğ‘¦) ğ‘™ğ‘œğ‘”(1 âˆ’ ğ‘)) = ğµğ¶ğ¸(ğ‘¦, ğ‘)
 ğ‘	      ğ‘ 

II. Ğ¡Ğ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ¸
Ğ¡Ğ²ĞµÑ€Ñ‚ĞºĞ° 1d, ÑĞ¼. Ñ€Ğ¸Ñ.: -5 = 3 * 1 + 7 * (-2) + 6.
ĞĞ±ÑƒÑ‡Ğ°ÑÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ° (ÑĞ´Ñ€Ğ° Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°).
Ğ¡Ğ²ĞµÑ€Ñ‚ĞºĞ° 2d, ÑĞ¼. Ñ€Ğ¸Ñ. - Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° ÑĞ²ĞµÑ€Ñ‚ĞºĞ¸; 3 - ÑĞ´Ñ€Ğ¾ ÑĞ²ĞµÑ€Ñ‚ĞºĞ¸.
12 = 3*0 + 3*1 + 2*2 + 0*2 + 0*2 + 1*0 + 3*0 + 1*1 + 2*2
ĞŸÑ€Ğ¸Ğ¼ĞµÑ€.
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
num_filters = 8
pd = 'same' # 'valid'
x = Conv2D(num_filters, kernel_size = 3, padding = pd, activation = 'relu')(x)
params = num_filters * (kernel_size^2 * n_channels + bias) = 8 * (9 * 3 + 1) = 224 # bias = 1, ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ
params = 16 * 9 * 8 = 1152 (bias = 0, use_bias = False)

III. Ğ¡Ğ»Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸  Ğ¿Ğ¾ Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼Ñƒ
Ğ¡Ğ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.
Ğ¡Ğ¼. Ñ€Ğ¸Ñ.
x = MaxPooling2D(pool_size = 2, strides = 2, padding = 'same')

IV. Ğ¡Ğ»Ğ¾Ğ¹ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.

Ğ’ ÑĞ»ÑƒÑ‡Ğ°Ğµ ĞĞ¡ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ ÑĞ»Ğ¾Ñ Ğ¿Ğ¾Ğ´Ğ°ĞµÑ‚ÑÑ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€ Ñ„Ğ¾Ñ€Ğ¼Ñ‹ (Ñ€Ğ°Ğ·Ğ¼ĞµÑ€_Ğ¿Ğ°ĞºĞµÑ‚Ğ°, ĞºĞ°Ñ€Ñ‚Ğ°_Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ²), Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ Ğ¿Ğ°ĞºĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ².
ĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² ĞĞ¡ Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹.
ĞŸĞ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ Ğ¿Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¼Ñƒ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñƒ (ÑĞ»ÑƒÑ‡Ğ°Ğ¹ Ğ¾Ğ´Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾Ğ¹ ĞºĞ°Ñ€Ñ‚Ñ‹ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ²):
Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ: Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ x Ğ¸Ğ· Ğ¿Ğ°ĞºĞµÑ‚Ğ° B = {x1, x2, ..., xm} (xi â€“ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°Ğº; m â€“ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¿Ğ°ĞºĞµÑ‚Ğ°);
Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Î³ Ğ¸ Î²; ĞºĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ğ° Îµ Ğ´Ğ»Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚Ğ¸.
Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ: {yi = BNÎ³, Î²(xi)}
Ğ¡Ğ¼. Ñ€Ğ¸Ñ.
ĞŸĞ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚:
- ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ¸Ñ‚ÑŒ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ¿Ğ°ĞºĞµÑ‚Ğ°;
- ÑƒÑĞºĞ¾Ñ€Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ¸ÑĞº Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ, Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğ¹;
- ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ ÑĞ»Ğ¾Ñ ÑĞµÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑÑ Ğ±Ğ¾Ğ»ĞµĞµ Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ Ğ¾Ñ‚ Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… ÑĞ»Ğ¾ĞµĞ²;
- Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ±Ğ¾Ğ»ĞµĞµ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (Ğ½Ğ° Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°Ñ… ÑĞ»Ğ¾Ñ ĞĞ¡ Ğ½ĞµÑ‚ Ñ‡Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¸Ğ»Ğ¸ Ğ¼Ğ°Ğ»Ñ‹Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹);
- Ğ¾ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ»ÑÑ‚ÑŒ, Ğ² Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾Ğ¹ Ğ¼ĞµÑ€Ğµ, Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ, Ğ¿Ğ¾ÑĞºĞ¾Ğ»ÑŒĞºÑƒ Ğ¿Ñ€Ğ¸Ğ²Ğ½Ğ¾ÑĞ¸Ñ‚ Ğ² Ğ²Ñ‹Ñ…Ğ¾Ğ´Ñ‹ ÑĞ»Ğ¾Ñ ĞĞ¡ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑˆÑƒĞ¼;
- ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ ĞĞ¡ Ğ¼ĞµĞ½ĞµĞµ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğº Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ²ĞµÑĞ¾Ğ².

V. ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ padding = 'same' / 'valid'

padding = 'same'
Model: "functional_1"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_layer (InputLayer)        â”‚ (None, 32, 32, 3)      â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization             â”‚ (None, 32, 32, 3)      â”‚            12 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)                 â”‚ (None, 32, 32, 8)      â”‚           224 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d (MaxPooling2D)    â”‚ (None, 16, 16, 8)      â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_1           â”‚ (None, 16, 16, 8)      â”‚            32 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)               â”‚ (None, 16, 16, 16)     â”‚         1,168 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1 (MaxPooling2D)  â”‚ (None, 8, 8, 16)       â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (Flatten)               â”‚ (None, 1024)           â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)               â”‚ (None, 1024)           â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                   â”‚ (None, 64)             â”‚        65,600 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (None, 10)             â”‚           650 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 67,686 (264.40 KB)
 Trainable params: 67,664 (264.31 KB)
 Non-trainable params: 22 (88.00 B)

padding = 'valid'
Model: "functional_1"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_layer (InputLayer)        â”‚ (None, 32, 32, 3)      â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization             â”‚ (None, 32, 32, 3)      â”‚            12 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)                 â”‚ (None, 30, 30, 8)      â”‚           224 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d (MaxPooling2D)    â”‚ (None, 15, 15, 8)      â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_1           â”‚ (None, 15, 15, 8)      â”‚            32 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)               â”‚ (None, 13, 13, 16)     â”‚         1,168 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1 (MaxPooling2D)  â”‚ (None, 6, 6, 16)       â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (Flatten)               â”‚ (None, 576)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)               â”‚ (None, 576)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                   â”‚ (None, 64)             â”‚        36,928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (None, 10)             â”‚           650 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 39,014 (152.40 KB)
 Trainable params: 38,992 (152.31 KB)
 Non-trainable params: 22 (88.00 B)

VI. ĞŸĞ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°ÑÑ‰Ğ¸Ğµ ÑĞ¾ÑÑ‚ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ ÑĞµÑ‚Ğ¸. GAN.

ĞŸĞ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°ÑÑ‰Ğ¸Ğµ ÑĞ¾ÑÑ‚ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ ÑĞµÑ‚Ğ¸ (ĞĞ¡, Generative Adversarial Networks, GAN) Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‚ÑÑ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ· ÑˆÑƒĞ¼Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ.
ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ MNIST ĞĞ¡ GAN Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ· ÑˆÑƒĞ¼Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ€ÑƒĞºĞ¾Ğ¿Ğ¸ÑĞ½Ñ‹Ñ… Ñ†Ğ¸Ñ„Ñ€.
ĞŸĞ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°ÑÑ‰Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ´Ğ²Ğµ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ ÑĞµÑ‚Ğ¸ â€“ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¸ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€.
Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ, Ğ¿Ğ¾Ğ½ÑÑ‚Ğ½Ğ¾, Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°ĞµÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€; Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€ ÑƒĞ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ÑĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ĞĞ¡:
- Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°Ñ‚ÑŒ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Ñ‚Ğ°Ğº, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ğ½Ğ¸ Ğ±Ñ‹Ğ»Ğ¸ Ğ½ĞµĞ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğ¼Ñ‹ Ğ¾Ñ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ², Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ MNIST;
  Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ğ² ÑĞ¾ÑÑ‚Ğ°Ğ²Ğµ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰ĞµĞ¹ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€, Ğ¸ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€;
- Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€ ÑƒÑ‡Ğ¸Ñ‚ÑÑ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Ğ¾Ñ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ².
Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ±ĞµÑ€ÑƒÑ‚ÑÑ Ğ¸Ğ· Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ° (ĞĞœ) Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….
Ğ’ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ ĞĞœ MNIST.
ĞĞ° Ğ²Ñ…Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¿Ğ¾Ğ´Ğ°ĞµÑ‚ÑÑ ÑˆÑƒĞ¼ â€“ Ğ¼Ğ°ÑÑĞ¸Ğ² noise Ñ„Ğ¾Ñ€Ğ¼Ñ‹ (batch_size, latent_dim)
Ğ’ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾Ğ¹ Ğ½Ğ¸Ğ¶Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğµ:
batch_size = 32
latent_dim = 100
Ğ¨ÑƒĞ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ:
import numpy as np
noise = np.random.normal(0, 1, (batch_size, latent_dim))
ĞĞ° Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€ Ñ„Ğ¾Ñ€Ğ¼Ñ‹ (batch_size, 28 * 28).
Ğ¦ĞµĞ»ÑŒ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ° â€“ Ğ½Ğ°ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ (Ğ¿Ğ¾Ğ´Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ) Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¾Ñ‚ Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ñ…,
Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ğ¾Ğ¹ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸:
Ğ¿Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñƒ Ñ€ĞµÑˆĞ¸Ñ‚ÑŒ, ÑÑ‚Ğ¾ Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼.
Ğ¦ĞµĞ»ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° â€“ Ğ½Ğ°ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸ĞµĞ¼ pgen,
Ñ‚Ğ°ĞºĞ¸Ğ¼, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€ Ğ½Ğµ ÑĞ¼Ğ¾Ğ³ Ğ±Ñ‹ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ pgen Ğ¾Ñ‚ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… pdata,
ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½Ğ°Ñ€ÑĞ´Ñƒ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ°.
Ğ¢Ğ°ĞºĞ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼, Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¿Ñ‹Ñ‚Ğ°ĞµÑ‚ÑÑ Ğ½Ğ°ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹,
Ğ° Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€ â€“ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¾Ñ‚ Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ñ….
ĞŸĞ¾ Ğ¼ĞµÑ€Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¸ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€, ÑĞ¾ÑÑ‚ÑĞ·Ğ°ÑÑÑŒ, Ğ¿Ğ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‚ Ğ´Ñ€ÑƒĞ³ Ğ´Ñ€ÑƒĞ³Ğ°.
ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ²ĞµĞ´ĞµÑ‚ÑÑ Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ñ… Ğ´Ğ²ÑƒÑ… Ğ²Ğ¸Ğ´Ğ¾Ğ² â€“ Ğ¿Ğ¾Ğ´Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ…, Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼,
Ğ¸ Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ñ…, Ğ²Ğ·ÑÑ‚Ñ‹Ñ… Ğ¸Ğ· Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, MNIST.
Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½ÑƒÑ ÑÑ…ĞµĞ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´Ğ°ÑÑ‰ĞµĞ¹ ÑĞ¾ÑÑ‚ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ¹ ÑĞµÑ‚Ğ¸ ÑĞ¼. Ğ½Ğ° Ñ€Ğ¸Ñ.
ĞœĞ¾Ğ´ĞµĞ»ÑŒ ĞĞ¡.
Model: "Generator"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_layer (InputLayer)        â”‚ (None, 100)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization             â”‚ (None, 100)            â”‚           400 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                   â”‚ (None, 256)            â”‚        25,856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ leaky_re_lu (LeakyReLU)         â”‚ (None, 256)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_1           â”‚ (None, 256)            â”‚         1,024 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (None, 512)            â”‚       131,584 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ leaky_re_lu_1 (LeakyReLU)       â”‚ (None, 512)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_2           â”‚ (None, 512)            â”‚         2,048 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)                 â”‚ (None, 1024)           â”‚       525,312 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ leaky_re_lu_2 (LeakyReLU)       â”‚ (None, 1024)           â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (Dense)                 â”‚ (None, 784)            â”‚       803,600 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 1,489,824 (5.68 MB)
 Trainable params: 1,488,088 (5.68 MB)
 Non-trainable params: 1,736 (6.78 KB)
ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ°
Model: "Discriminator"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_layer_1 (InputLayer)      â”‚ (None, 784)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_4 (Dense)                 â”‚ (None, 512)            â”‚       401,920 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ leaky_re_lu_3 (LeakyReLU)       â”‚ (None, 512)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_5 (Dense)                 â”‚ (None, 512)            â”‚       262,656 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ leaky_re_lu_4 (LeakyReLU)       â”‚ (None, 512)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_6 (Dense)                 â”‚ (None, 1)              â”‚           513 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 665,089 (2.54 MB)
 Trainable params: 665,089 (2.54 MB)
 Non-trainable params: 0 (0.00 B)
ĞĞ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
Model: "Combined"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_layer_2 (InputLayer)      â”‚ (None, 100)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Generator (Functional)          â”‚ (None, 784)            â”‚     1,489,824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Discriminator (Functional)      â”‚ (None, 1)              â”‚       665,089 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,154,913 (8.22 MB)
 Trainable params: 1,488,088 (5.68 MB)
 Non-trainable params: 666,825 (2.54 MB)
ĞšĞ¾Ğ´ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ĞĞ¡:
from keras.layers import Input, Dense
from keras.layers import BatchNormalization, LeakyReLU
from keras.models import Model
from keras.optimizers import Adam
img_rows = 28
img_cols = 28
img_shape = (img_rows * img_cols,)
latent_dim = 100
loss_d = 'binary_crossentropy'
loss_c = 'binary_crossentropy'
optimizer_d = Adam(0.0002, 0.5)
optimizer_c = Adam(0.0002, 0.5)
def one_g_dense(units, x):
    x = BatchNormalization(momentum = 0.8)(x)
    x = Dense(units)(x)
    return LeakyReLU(alpha = 0.2)(x)
def one_d_dense(units, x):
    x = Dense(units)(x)
    return LeakyReLU(alpha = 0.2)(x)
# Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€
def build_generator():
    inp = Input(shape = (latent_dim,))
    x = one_g_dense(256, inp)
    x = one_g_dense(512, x)
    x = one_g_dense(1024, x)
    x = Dense(784, activation = 'tanh')(x)
    generator = Model(inp, x, name = 'Generator')
    generator.summary()
    return generator
# Ğ”Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€
def build_discriminator():
    img = Input(shape = img_shape)
    x = one_d_dense(512, img)
    x = one_d_dense(256, x)
    x = one_d_dense(128, x)
    output = Dense(1, activation = 'sigmoid')(x)
    discriminator = Model(img, output, name = 'Discriminator')
    discriminator.summary()
    discriminator.compile(loss = loss_d, optimizer = optimizer_d, metrics = ['accuracy'])
    return discriminator
# ĞĞ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
def build_combined(generator, discriminator):
    # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ ÑˆÑƒĞ¼ Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ (Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚) Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
    inp = Input(shape = (latent_dim,))
    img = generator(inp)
    # Ğ”Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€ Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
    # Ğ¸ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµÑ‚ ĞµĞ³Ğ¾ Ğ»Ğ¸Ğ±Ğ¾ ĞºĞ°Ğº Ğ¸ÑÑ‚Ğ¸Ğ½Ğ½Ğ¾Ğµ, Ğ»Ğ¸Ğ±Ğ¾ ĞºĞ°Ğº Ğ¿Ğ¾Ğ´Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ñ validity
    output = discriminator(img)
    # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    combined = Model(inp, output, name = 'Combined')
    # ĞŸĞ¾ÑĞºĞ¾Ğ»ÑŒĞºÑƒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ° Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ°, Ñ‚Ğ¾ Ğ¿Ğ¾ÑĞ»Ğµ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ ÑĞ¿Ğ¾Ñ…Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑÑÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸
    combined.compile(loss = loss_c, optimizer = optimizer_c)
    combined.summary()
    return combined
generator = build_generator() # ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
discriminator = build_discriminator() # ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»ÑÑ†Ğ¸Ñ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ°
combined = build_combined(generator, discriminator)

Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ĞĞœ.
x_trn = load_train()
x_trn = 2.0 * x_trn - 1.0 # ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñƒ [-1, 1] (gen_activation = 'tanh')

ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.
steps = 30001
batch_size = 32
sample_interval = 3000
train(discriminator, generator, combined)
def train(discriminator, generator, combined):
    # ĞœĞµÑ‚ĞºĞ¸ Ğ¸ÑÑ‚Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ (Ğ¿Ğ¾Ğ´Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ…: valid - 1)
    valid = np.ones((batch_size, 1))
    d_loss, d_acc, g_loss = [], [], []
    for step in range(steps):
        print(step)
        # ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€
        # Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ batch_size ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ· Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ°
        idx = np.random.randint(0, x_trn.shape[0], batch_size)
        imgs = x_trn[idx]
        # Ğ¨ÑƒĞ¼, Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ batch_size Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ (Ğ¿Ğ¾Ğ´Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ…)
        gen_imgs = generator.predict(noise)
        # ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€, Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ°Ñ ĞµĞ¼Ñƒ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğµ, Ğ° Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¿Ğ¾Ğ´Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
        discriminator.trainable = True
        d_hist_real = discriminator.train_on_batch(imgs, valid)
        d_hist_fake = discriminator.train_on_batch(gen_imgs, valid - 1)
        # Ğ£ÑÑ€ĞµĞ´Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑÑ€ĞµĞ´Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ
        d_hist = 0.5 * np.add(d_hist_real, d_hist_fake)
        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€
        discriminator.trainable = False
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°. ĞœĞµÑ‚ĞºĞ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ valid (ĞµĞ´Ğ¸Ğ½Ğ¸Ñ†Ñ‹),
        # Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¿Ñ€Ğ¸ ĞµĞ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸, ÑÑ‡Ğ¸Ñ‚Ğ°ÑÑ‚ÑÑ Ğ¸ÑÑ‚Ğ¸Ğ½Ğ½Ñ‹Ğ¼Ğ¸
        g_ls = combined.train_on_batch(noise, valid)
        if step % 100 == 0:
            d_loss.append(d_hist[0])
            d_acc.append(d_hist[1])
            g_loss.append(g_ls)
        # ĞŸĞ¾Ñ‚ĞµÑ€Ğ¸ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        if step % (sample_interval / 10) == 0:
            print("%d [D loss: %f, acc.: %.2f%%] [G loss: %f]" % (step, d_hist[0], 100 * d_hist[1], g_ls))
        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€Ğ¸ÑÑƒĞ½Ğ¾Ğº Ñ 25-Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸
        if step % sample_interval == 0:
            save_sample_images(latent_dim, generator, step)
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ² Ñ„Ğ°Ğ¹Ğ»
    file_gen = pathToHistory + 'generator_model_%03d.keras' % steps
    generator.save(file_gen)
    print('ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ° Ğ² Ñ„Ğ°Ğ¹Ğ»', file_gen)
    #
    # Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹
    fn_d_loss, fn_d_acc, fn_g_loss = 'd_loss.txt', 'd_acc.txt', 'g_loss.txt'
    print('Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹:\n' + fn_d_loss + '\n' + fn_d_acc + '\n' + fn_g_loss)
    print('ĞŸÑƒÑ‚ÑŒ:', pathToHistory)
    with open(pathToHistory + fn_d_loss, 'w') as output:
        for val in d_loss: output.write(str(val) + '\n')
    with open(pathToHistory + fn_d_acc, 'w') as output:
        for val in d_acc: output.write(str(val) + '\n')
    with open(pathToHistory + fn_g_loss, 'w') as output:
        for val in g_loss: output.write(str(val) + '\n')
    # Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
    yMax = max(g_loss)
    cnt = len(g_loss)
    rng = np.arange(cnt)
    fig, ax = plt.subplots(figsize = (7, 4))
    ax.scatter(rng, d_loss, marker = 'o', c = 'blue', edgecolor = 'black')
    ax.scatter(rng, g_loss, marker = 'x', c = 'red')
    ax.set_title('ĞŸĞ¾Ñ‚ĞµÑ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° (x) Ğ¸ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ° (o)')
    ax.set_ylabel('ĞŸĞ¾Ñ‚ĞµÑ€Ğ¸')
    ax.set_xlabel('Ğ­Ğ¿Ğ¾Ñ…Ğ° / 100')
    ax.set_xlim([-0.5, cnt])
    ax.set_ylim([0, 1.1 * yMax])
    fig.show()
Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
def save_sample_images(latent_dim, generator, step):
    r, c = 5, 5 # Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ 25 Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
    # latent_dim - Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ ÑˆÑƒĞ¼Ğ°, Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ°ĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
    noise = np.random.normal(0, 1, (r * c, latent_dim))
    gen_imgs = generator.predict(noise)
    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ÑÑ Ğº Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñƒ [0, 1]
    gen_imgs = 0.5 * gen_imgs + 0.5
    gen_imgs = gen_imgs.reshape(-1, 28, 28)
    fig, axs = plt.subplots(r, c)
    cnt = 0
    for i in range(r):
        for j in range(c):
            axs[i, j].imshow(gen_imgs[cnt], cmap = 'gray')
            axs[i, j].axis('off')
            cnt += 1
    fig.savefig(pathToHistory + '%d.png' % step)
    plt.close()
Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ ÑĞ¼. Ğ½Ğ° Ñ€Ğ¸Ñ.

VII. cGAN

ĞĞ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° MNIST.
Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ GAN Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ»Ğ°ÑÑĞ°.
ĞšĞ»Ğ°ÑÑ Ğ·Ğ°Ğ´Ğ°ĞµÑ‚ÑÑ Ğ¼ĞµÑ‚ĞºĞ¾Ğ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾ÑÑ‚ÑƒĞ¿Ğ°ĞµÑ‚ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´Ñ‹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ°.
Ğ”Ğ°Ğ»ĞµĞµ Ğ¼ĞµÑ‚ĞºĞ° Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ÑÑ Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€ (ÑĞ»Ğ¾Ğ¹ Embedding).
Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ ÑĞ¼. Ğ½Ğ° Ñ€Ğ¸Ñ.

ĞĞ±Ñ‰Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ. Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ¸ Ğ¸ Ğ²Ñ…Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°.
x_trn, y_trn = load_data('train')
x_trn = 2.0 * x_trn - 1.0 # ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñƒ [-1, 1] (gen_activation = 'tanh')
num_classes = 10
latent_dim = 100
noise = Input((latent_dim,))
label = Input((1,)) # ĞœĞµÑ‚ĞºĞ° ĞºĞ»Ğ°ÑÑĞ°
inp_c = [noise, label] # Ğ’Ñ…Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
optimizer_d = Adam(0.0002, 0.5)
optimizer_c = Adam(0.0002, 0.5)
n_steps = 30001 # Ğ§Ğ¸ÑĞ»Ğ¾ ÑˆĞ°Ğ³Ğ¾Ğ² Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (60001)
batch_size = 32 # Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¿Ğ°ĞºĞµÑ‚Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹)
sample_interval = 3000 # Ğ˜Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸ĞµĞ¼ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ² Ñ„Ğ°Ğ¹Ğ»
file_gen = 'gen_model_%03d.keras' % n_steps

ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞºĞ°Ğ»ÑÑ€Ğ° Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€.
from keras.layers import multiply, Embedding, Flatten
# Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ…Ğ¾Ğ´Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ°.
def one_emb(num_classes, emb_dim, inp_g_d, label):
    lbl = Embedding(num_classes, emb_dim)(label)
    lbl = Flatten()(lbl)
    inp_gen_dis = multiply([inp_g_d, lbl])
    return inp_gen_dis
# Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€
def build_generator():
    inp_gen = one_emb(num_classes, latent_dim, noise, label)
    x = one_g_dense(inp_gen, 256)
    x = one_g_dense(x, 512)
    x = one_g_dense(x, 1024)
    out = Dense(784, activation = 'tanh')(x)
    generator = Model(inp_c, out, name = 'Generator')
    return generator
# Ğ”Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€
def build_discriminator():
    img = Input((784,))
    inp_dis = one_emb(num_classes, 784, img, label)
    x = one_d_dense(inp_dis, 512)
    x = one_d_dense(x, 256)
    x = one_d_dense(x, 128)
    out = Dense(1, activation = 'sigmoid')(x)
    discriminator = Model([img, label], out, name = 'Discriminator')
    discriminator.compile(loss = 'binary_crossentropy', optimizer = optimizer_d, metrics = ['accuracy'])
    return discriminator
# cGAN
def build_combined():
    gen_img = generator(inp_c)
    inp_d = [gen_img, label]
    out = discriminator(inp_d)
    combined = Model(inp_c, out, name = 'combined')
    combined.compile(loss = 'binary_crossentropy', optimizer = optimizer_c)
    return combined
# Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
def m_inp(N):
    idx = np.random.randint(0, x_trn.shape[0], N)
    d_n = x_trn[idx]
    l_n = y_trn[idx] # ĞœĞµÑ‚ĞºĞ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
    g_n_noise = np.random.normal(0, 1, (N, latent_dim))
    return d_n, l_n, g_n_noise
# ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
def train():
    # ĞœĞµÑ‚ĞºĞ¸ Ğ¸ÑÑ‚Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ (Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ñ…: valid - 1)
    valid = np.ones(bath_size)
    for step in range(n_steps):
        # Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ñ…Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        d_n, l_n, g_n_noise = m_inp(batch_size)
        inp_gen = [g_n_noise, l_n] # Ğ¨ÑƒĞ¼ Ğ¸ Ğ¼ĞµÑ‚ĞºĞ¸
        inp_d = [d_n, l_n] # Ğ˜ÑÑ‚Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ğ¼ĞµÑ‚ĞºĞ¸
        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ batch_size Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
        gen_imgs = generator.predict(inp_gen)
        inp_d2 = [gen_imgs, l_n] # Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ğ¼ĞµÑ‚ĞºĞ¸
        # ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€
        discriminator.trainable = True
        d_hist_real = discriminator.train_on_batch(inp_d, valid)
        d_hist_fake = discriminator.train_on_batch(inp_d2, valid - 1)
        # Ğ£ÑÑ€ĞµĞ´Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑÑ€ĞµĞ´Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ
        d_ls, d_a = 0.5 * np.add(d_hist_real, d_hist_fake)
        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€
        sampled_labels = np.random.randint(0, num_classes, bath_size)
        inp_gen = [g_n_noise, sampled_labels]
        discriminator.trainable = False
        g_ls = combined.train_on_batch(inp_gen, valid)
        # ĞŸĞ¾Ñ‚ĞµÑ€Ğ¸ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        if step % (sample_interval / 10) == 0:
            print("%d [D loss: %f, acc: %.2f%%] [G loss: %f]" % (step, d_ls, 100 * d_a, g_ls))
        if step % sample_interval == 0: # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€Ğ¸ÑÑƒĞ½Ğ¾Ğº
            save_sample_images()

# Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
generator = build_generator()
discriminator = build_discriminator() # ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»ÑÑ†Ğ¸Ñ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ°
combined = build_combined() # ĞĞ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
train()
generator.compile() # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ² Ñ„Ğ°Ğ¹Ğ»
generator.save(file_gen)

Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·
from keras.models import load_model 
x_tst, y_tst = load_data('test')
x_tst = 2.0 * x_tst - 1.0 # ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñƒ [-1, 1] (gen_activation = 'tanh')
generator = load_model(file_gen)
N = 20
d_n, l_n, g_n_noise = m_inp(N)
gen_imgs = generator.predict([g_n_noise, l_n])
d_n = 0.5 * d_n + 0.5 # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ÑÑ Ğº Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñƒ [0, 1]
gen_imgs = 0.5 * gen_imgs + 0.5
fig, axs = plt.subplots(2, N, figsize = (12, 2.5))
fig.suptitle('ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…')
for i in range(N):
    axs[0, i].title.set_text(l_n[i])
    axs[0, i].imshow(d_n[i].reshape(28, 28), cmap = 'gray')
    axs[1, i].title.set_text(l_n[i])
    axs[1, i].imshow(gen_imgs[i].reshape(28, 28), cmap = 'gray')
    for k in range(2): axs[k, i].axis('off')
plt.show()

VIII. Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ GAN
Ğ¡Ğ¼. doc-Ñ„Ğ°Ğ¹Ğ».

IX. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ°/Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
import numpy as np
from skimage.metrics import mean_squared_error
import cv2, scipy
from skimage.metrics import structural_similarity as ssim
from scipy.spatial.distance import euclidean as e_dist
#
sz = 784 * 3
image1 = np.arange(sz).reshape(28, 28, 3) / sz
image2 = np.arange(sz).reshape(28, 28, 3) / sz + 0.1
#
# Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°
mse = ((image1 - image2) ** 2).mean()
mse2 = mean_squared_error(image1, image2)
# ĞŸĞ¸ĞºĞ¾Ğ²Ğ¾Ğµ Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ° Ğº ÑˆÑƒĞ¼Ñƒ
# https://habr.com/ru/articles/126848/
psnr = cv2.PSNR(image1, image2, mse)
# Ğ˜Ğ½Ğ´ĞµĞºÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğ³Ğ¾ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ°
# https://habr.com/ru/articles/126848/
# https://scikit-image.org/docs/stable/auto_examples/transform/plot_ssim.html
score_ssim, diff = ssim(image1, image2, full = True, multichannel = True)
Ğ¸Ğ»Ğ¸ (Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ğ²ĞµÑ€ÑĞ¸Ğ¸)
score_ssim, diff = ssim(image1, image2, full = True, channel_axis = 2)
score_ssim2, diff = ssim(image1.flatten(), image2.flatten(), full = True)
# Ğ•Ğ²ĞºĞ»Ğ¸Ğ´Ğ¾Ğ²Ğ¾ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
ec_dst = np.linalg.norm(image1 - image2)
ec_dst2 = e_dist(image1.flatten(), image2.flatten())
# ĞšĞ¾ÑĞ¸Ğ½ÑƒÑĞ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸
# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html
cs_dst = scipy.spatial.distance.cosine(image1.flatten(), image2.flatten())

print('mse =', mse)
print('mse2 =', mse2)
print('psnr =', psnr)
print('ssim =', score_ssim)
print('ssim2 =', score_ssim2)
print('ec_dst =', ec_dst)
print('ec_dst2 =', ec_dst2)
print('cs_dst =', cs_dst)
mse = 0.009999999999999998
mse2 = 0.009999999999999998
psnr = -19.99999999999996
ssim = 0.9676383577979917
ssim2 = 0.9281674094684876
ec_dst = 4.8497422611928585
ec_dst2 = 4.849742261192823
cs_dst = 0.002826967506080802

X. ĞœĞµÑ‚Ğ¾Ğ´ ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾
 ĞŸĞ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ñ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¾Ğ¹ Ñ€ĞµÑˆĞ¸Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ² Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğ¸ 
 Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ³Ğ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ².
 ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ñ‡Ğ¸ÑĞ»Ğ¾ "Ğ¿Ğ¸" Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼:
 1. Ğ—Ğ°Ğ´Ğ°Ñ‚ÑŒ ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚ ÑĞ¾ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ¾Ğ¹ 2R. ĞŸĞ¾Ğ¼ĞµÑÑ‚Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‚Ñ€ ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ° Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚.
    Ğ¡Ñ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹ ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ° Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹ Ğ¾ÑÑĞ¼ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚.
 2. N = 1000 - Ñ‡Ğ¸ÑĞ»Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ².
 3. n = 0 - Ñ‡Ğ¸ÑĞ»Ğ¾ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‚Ğ¾Ñ‡ĞµĞº, Ğ¿Ğ¾Ğ¿Ğ°Ğ²ÑˆĞ¸Ñ… Ğ²Ğ¾ Ğ²Ğ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ğ¹ Ğ² ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚ ĞºÑ€ÑƒĞ³ Ñ€Ğ°Ğ´Ğ¸ÑƒÑĞ° R.
 4. Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ N Ñ€Ğ°Ğ·:
  4.1. Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½ÑƒÑ Ñ‚Ğ¾Ñ‡ĞºÑƒ Ñ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ°Ğ¼Ğ¸ x, y: -R <= x <= R, -R <= y <= R.
  4.2. Ğ•ÑĞ»Ğ¸ x^2 + y^2 <= R^2:
         n +=1
 5. Ğ¿Ğ¸ = 4 * n / N.

import numpy as np
r = 10
r2 = r**2
N = 500000
n = 0
for k in range(N):
    p = np.random.uniform(-r, r, 2)
    if p[0]**2 + p[1]**2 <= r2: n += 1
print('Ğ¿Ğ¸ =', 4 * n / N)


XI. ĞšĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°.
 - ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ - Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ°Ğ¼ Ğ»ĞµĞºÑ†Ğ¸Ğ¸;
 - Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° Ğ½Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ°/Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´ ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾.
   Ğ—Ğ°Ğ´Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ° MNIST (Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞµ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¾Ñ‡Ğ½Ğ¾Ğµ).
   ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ² Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğµ Ğ´Ğ²Ğ° Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ†Ğ¸Ñ„Ñ€ 1 Ğ¸ 7,
   Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¿Ğ¾Ğ¾Ñ‡ĞµÑ€ĞµĞ´Ğ½Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸:
    - ÑÑ€ĞµĞ´Ğ½ÑÑ ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°; MeanSquaredError class
    - ĞµĞ²ĞºĞ»Ğ¸Ğ´Ğ¾Ğ²Ğ¾ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ;
    â€“ ĞºĞ¾ÑĞ¸Ğ½ÑƒÑĞ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ;
    - Ğ¸Ğ½Ğ´ĞµĞºÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğ³Ğ¾ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ°.
   Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ²Ñ‹Ğ²ĞµÑÑ‚Ğ¸ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ, Ğ¸Ğ½Ğ´ĞµĞºÑÑ‹ Ğ¸ Ñ€Ğ¸ÑÑƒĞ½ĞºĞ¸ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹.
   Ğ”Ğ»Ñ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑŠĞµĞ¼Ğ° Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´ ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾.

XII. Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ¸ 11 Ğ¸ 12

Ğ ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ².

Ğ›Ğ  11. ĞĞ¡ ÑĞ¾ ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ»Ğ¾ÑĞ¼Ğ¸.
Ğ§Ğ¸ÑĞ»Ğ¾ ÑĞ¿Ğ¾Ñ… - Ğ½Ğµ Ğ¼ĞµĞ½ĞµĞµ 20.
ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´ÑÑ‚ÑÑ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ ĞĞ¡, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ñ… Ğ² Ñ‚Ğ¾Ğ¼ Ñ‡Ğ¸ÑĞ»Ğµ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑĞ»Ğ¾Ğ¸:
- ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ, Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ´Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸;
- ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸;
- ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¸ Ğ¿Ğ¾Ğ´Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸;
- ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ.
Ğ’ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğµ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´ÑÑ‚ÑÑ:
- model.summary();
- Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ;
- classification_report;
- Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ÑĞ¾ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ°Ñ Ğ² Ñ‚Ğ¾Ğ¼ Ñ‡Ğ¸ÑĞ»Ğµ:
  - Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²;
  - Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ.
ĞĞ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹.

Ğ›Ğ  12. cGAN Ñ MNIST.
Ğ’ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğµ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´ÑÑ‚ÑÑ:
- model.summary();
- Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ;
- Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ;
- Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:
   - Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ· ĞĞœ Ñ Ğ¼ĞµÑ‚ĞºĞ°Ğ¼Ğ¸, Ğ¿Ğ¾ÑÑ‚ÑƒĞ¿Ğ¸Ğ²ÑˆĞ¸Ğ¼Ğ¸ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°;
   - ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¸Ğ¼ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.
ĞĞ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€) ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ÑÑ Ğ² Ñ„Ğ°Ğ¹Ğ»,
ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°.

